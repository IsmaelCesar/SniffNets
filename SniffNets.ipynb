{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ichkaQU9wv0"
   },
   "source": [
    "# SniffNets\n",
    "\n",
    "This notebook contains the implementation of the SniffNets models created for clasifying the codification of signals deteced from artificial noses\n",
    "\n",
    "* Disclaimer: Unfortunately the Coffee dataset is not publicly available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BspHMr3muCY"
   },
   "outputs": [],
   "source": [
    "# Run this block it you are using google colaboratory and desire to save the results in\n",
    "# google drive\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "zAeaH-UMCgUC",
    "outputId": "2ba9600a-3300-4839-80ba-6669ad9c6654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SniffNets'...\n",
      "remote: Enumerating objects: 182, done.\u001b[K\n",
      "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
      "remote: Compressing objects: 100% (118/118), done.\u001b[K\n",
      "remote: Total 775 (delta 123), reused 115 (delta 59), pack-reused 593\u001b[K\n",
      "Receiving objects: 100% (775/775), 178.63 MiB | 29.92 MiB/s, done.\n",
      "Resolving deltas: 100% (424/424), done.\n",
      "Checking out files: 100% (132/132), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/IsmaelCesar/SniffNets.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cH1QOvNd-fQM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import logging\n",
    "import pickle as pkl\n",
    "%tensorflow_version 1.x\n",
    "import keras\n",
    "from keras.layers import Conv2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Flatten,Dropout,Add\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "import sklearn\n",
    "import sklearn.neighbors.KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global data_folder,data_sets,ds_wine,extension\n",
    "global dataset_name,sub_dataset_name,experiments_folder\n",
    "\n",
    "data_folder = \"SniffNets/data/\"\n",
    "global_dir = \"drive/My Drive/\"\n",
    "\n",
    "experiments_folder = os.path.join(global_dir,\"windowed_experiments_mean_stdd/\")\n",
    "\n",
    "if not os.path.exists(experiments_folder):\n",
    "    os.mkdir(experiments_folder)\n",
    "dataset_name=\"\"\n",
    "sub_dataset_name=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z52U5zawDeNp"
   },
   "source": [
    "### Data Loading resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nhWulvJDFwR"
   },
   "outputs": [],
   "source": [
    "extension = \".pkl\"\n",
    "data_sets   = {\n",
    "    \"fonollosa\":{0: \"B1-system\",\n",
    "                 1: \"B2-system\",\n",
    "                 2: \"B3-system\",\n",
    "                 3: \"B4-system\",\n",
    "                 4: \"B5-system\",\n",
    "                 \"n_classes\": 4\n",
    "                 },\n",
    "    \"turbulent_gas_mixtures\": {0: \"preloaded_dataset\", \"n_classes\": 4},\n",
    "    \"windtunnel\": {\n",
    "                0: \"preloaded_dataset-L1\",\n",
    "                1: \"preloaded_dataset-L2\",\n",
    "                2: \"preloaded_dataset-L3\",\n",
    "                3: \"preloaded_dataset-L4\",\n",
    "                4: \"preloaded_dataset-L5\",\n",
    "                5: \"preloaded_dataset-L6\",\n",
    "                \"n_classes\": 11,\n",
    "                }\n",
    "    # Un comment the following line if you have been authorized to use the dataset\n",
    "    # ,\"coffee_dataset\": {0: \"preloaded_dataset\", \"n_classes\": 3}\n",
    "}\n",
    "ds_wine = {\"QWines-CsystemTR\":3,\n",
    "            \"QWinesEa-CsystemTR\":4}\n",
    "\n",
    "def load(ds_choice, ds_idx=0):\n",
    "    \"\"\"\n",
    "    choices : 0 -> fonollosa, 1 -> turbulent_gas_mixtures, 2 -> windtunnel\n",
    "    :param ds_choice: the index naming the dataset chosen\n",
    "    :param ds_idx: the index if the folder containing the dataset has one or more datasets\n",
    "    :return: the dataset read,the labels and  the number of classes\n",
    "    \"\"\"\n",
    "    global data_folder, data_sets, extension, dataset_name, sub_dataset_name\n",
    "    assert ds_choice in list(data_sets.keys())\n",
    "    # ds_name =[ds_choice]\n",
    "    ds_name = ds_choice\n",
    "    dataset_name = ds_name+\"/\"\n",
    "\n",
    "    logging.info(ds_name + \" Is being loaded\")\n",
    "\n",
    "    n_classes = data_sets[ds_name]['n_classes']\n",
    "    print(\"\\n\\n ds_name:\"+ds_name+\"\\n\\n\")\n",
    "    print(\"\\n\\n ds_idx\"+str(ds_idx)+\"\\n\\n\")\n",
    "    subds_name = data_sets[ds_name][ds_idx]\n",
    "    sub_dataset_name = subds_name + \"/\"\n",
    "\n",
    "    data ,labels = None,None\n",
    "    with open(data_folder+ds_name+\"/\"+subds_name+extension, 'rb') as d:\n",
    "        data, labels, _ = pkl.load(d)\n",
    "        d.close()\n",
    "\n",
    "    return data, labels, n_classes, dataset_name, sub_dataset_name\n",
    "\n",
    "def load_wine(ds_choice):\n",
    "    \"\"\"\n",
    "    choices : 0 -> QWines-CsystemTR, 1 -> QWinesEa-CsystemTR\n",
    "    :param ds_choice: the index naming the dataset chosen\n",
    "    :param ds_idx: the index if the folder containing the dataset has one or more datasets\n",
    "    :return: the dataset read,the labels and  the number of classes\n",
    "    \"\"\"\n",
    "    global data_folder, ds_wine, extension\n",
    "\n",
    "    assert ds_choice in list(ds_wine.keys())\n",
    "    ds_name = ds_choice\n",
    "    dataset_name = ds_name+'/'\n",
    "\n",
    "    logging.info(ds_name + \" Is being loaded\")\n",
    "\n",
    "    n_classes = ds_wine[ds_name]\n",
    "\n",
    "    data,labels = None,None\n",
    "    with open(data_folder+\"wines/\"+ds_name+extension,\"rb\") as d:\n",
    "        data, labels, _, _ = pkl.load(d)\n",
    "        d.close()\n",
    "\n",
    "    return data, labels, n_classes, dataset_name, sub_dataset_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NiH3EN-REPJ3"
   },
   "outputs": [],
   "source": [
    "def data_set_reshaped(data_set):\n",
    "    newData = []\n",
    "    for d in data_set:\n",
    "        newData.append(d.reshape(d.shape[0], d.shape[1],1).tolist())\n",
    "    return np.array(newData)\n",
    "\n",
    "def load_and_split(ds_choice,ds_idx=0,read_wine_datasets=False):\n",
    "    # Loading dataset\n",
    "    global input_shape,n_classes,dataset_name,sub_dataset_name\n",
    "    data = None\n",
    "    labels = None\n",
    "    if not read_wine_datasets:\n",
    "        data, labels, n_classes,dataset_name,sub_dataset_name = load(ds_choice,ds_idx)\n",
    "    else:\n",
    "        data, labels, n_classes, dataset_name, sub_dataset_name = load_wine(ds_choice)\n",
    "\n",
    "    train_data, test_data,train_labels, test_labels = train_test_split(data,labels,test_size=.2)\n",
    "    train_data = data_set_reshaped(train_data)\n",
    "    test_data  = data_set_reshaped(test_data)\n",
    "\n",
    "    input_shape = train_data[0].shape\n",
    "\n",
    "    train_data,train_labels =   sklearn.utils.shuffle(train_data,train_labels)\n",
    "    test_data, test_labels = sklearn.utils.shuffle(test_data, test_labels)\n",
    "\n",
    "\n",
    "    return train_data,train_labels,test_data,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tev9_C_6OHZv"
   },
   "outputs": [],
   "source": [
    "def standardize_data(train_data, test_data, input_shape):\n",
    "\n",
    "    flat_train_data = train_data.reshape(train_data.shape[0], input_shape[0] * input_shape[1])\n",
    "    flat_test_data = test_data.reshape(test_data.shape[0], input_shape[0] * input_shape[1])\n",
    "\n",
    "    scaler = sklearn.preprocessing.StandardScaler().fit(flat_train_data)\n",
    "    flat_train_data = scaler.transform(flat_train_data)\n",
    "\n",
    "    scaler = sklearn.preprocessing.StandardScaler().fit(flat_test_data)\n",
    "    flat_test_data = scaler.transform(flat_test_data)\n",
    "\n",
    "    new_train = flat_train_data.reshape(train_data.shape[0], input_shape[0], input_shape[1], 1)\n",
    "    new_test = flat_test_data.reshape(test_data.shape[0], input_shape[0], input_shape[1], 1)\n",
    "    return new_train, new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXhok4FGlWW-"
   },
   "outputs": [],
   "source": [
    "def split_datasamples_by_sensors(data):\n",
    "    shape = data.shape\n",
    "    new_split = []\n",
    "    # Iterate over data columns\n",
    "    for i in range(shape[2]):\n",
    "        new_split.append(data[:, :, i])\n",
    "        new_split[i] = new_split[i].reshape(new_split[i].shape[0], new_split[i].shape[1])\n",
    "    return new_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5HQ6vrgDmgU"
   },
   "source": [
    "### Models Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LljkgGLN9k7P"
   },
   "outputs": [],
   "source": [
    "def sniffnet(input_shape,n_classes):\n",
    "    kernel = (20, input_shape[1] // 2 - 1)\n",
    "    multiplier = 10\n",
    "    out_channels = 5 * multiplier\n",
    "    # convolutional components\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(out_channels, kernel, input_shape=input_shape, use_bias=True,\n",
    "                    activation='relu', name='first_conv'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    kernel = ((input_shape[0]-kernel[0]+1)//2, kernel[1])\n",
    "    model.add(Conv2D(out_channels, kernel, use_bias=True,\n",
    "                    activation='relu', name='second_conv'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(AveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(out_channels, use_bias=True, activation='relu', name=\"camada_fc1\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(n_classes, use_bias=True, activation='softmax', name=\"classificaiton\"))\n",
    "\n",
    "    return model\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9DaXw0HTRkA4"
   },
   "outputs": [],
   "source": [
    "def sniffresnet(input_shape, n_classes):\n",
    "    multiplier = 4\n",
    "    kernel = (8, input_shape[1] // 2 - 1)\n",
    "    out_channels = 5 * multiplier\n",
    "    # First Part of the convolution\n",
    "    X_input = Input(input_shape)\n",
    "    X_skip = Conv2D(out_channels, kernel, activation='relu', name='first_conv1')(X_input)\n",
    "    X = Conv2D(out_channels, kernel, padding='same', activation='relu', name='first_conv2')(X_skip)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Add()([X, X_skip])\n",
    "    X = MaxPooling2D((2, 1), padding='same', name=\"max_pool1\")(X)\n",
    "\n",
    "    # Second Part of the convolution\n",
    "    out_channels = out_channels * multiplier\n",
    "    X_skip = Conv2D(out_channels, kernel, activation='relu', name='second_conv1')(X)\n",
    "    X = Conv2D(out_channels, kernel, padding='same', use_bias=True, activation='relu', name='second_conv2')(X_skip)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Add()([X, X_skip])\n",
    "    X = MaxPooling2D((2, 1), name=\"max_pool2\")(X)\n",
    "\n",
    "    # Fully Connected Part\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(100, use_bias=True, activation=\"relu\", name=\"fc1\")(X)\n",
    "    X = Dropout(.25)(X)\n",
    "    X = Dense(n_classes, use_bias=True, activation=\"softmax\", name=\"class\")(X)\n",
    "\n",
    "    model = Model(inputs=X_input, outputs=X, name=\"SniffResnet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQ7OXXIclSU3"
   },
   "outputs": [],
   "source": [
    "def sniffmultinose(input_shape,n_classes):\n",
    "    inputs_list = []\n",
    "    multinose_out = []\n",
    "    for i in range(input_shape[1]):\n",
    "        X_input = Input((input_shape[0],), name=(\"input_nose_\" + str(i)))\n",
    "        inputs_list.append(X_input)\n",
    "        X = Dense(input_shape[0], input_shape=(input_shape[0],),\n",
    "                  use_bias=True, activation='relu', name=(\"fc1_nose_\" + str(i)))(X_input)\n",
    "        X = Dense(input_shape[0] // 4, use_bias=True, activation='tanh', name=(\"fc2_nose_\" + str(i)))(X)\n",
    "        X = Dense(input_shape[0] // 8, use_bias=True, activation='tanh', name=(\"fc3_nose_\" + str(i)))(X)\n",
    "        multinose_out.append(X)\n",
    "\n",
    "    concat = concatenate(multinose_out)\n",
    "\n",
    "    X = Dense(100, activation='tanh', use_bias=True)(concat)\n",
    "    X = Dense(100, activation='relu', use_bias=True)(X)\n",
    "    X_out = Dense(n_classes, activation='softmax', name=\"class\")(X)\n",
    "\n",
    "    model = Model(inputs=inputs_list, outputs=X_out, name=\"SniffNetMultiNose\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2b0PTwVELw5r"
   },
   "outputs": [],
   "source": [
    "def get_knn_classifier(n_neighbors): \n",
    "    return KNN(n_neighbors=3)\n",
    "\n",
    "def get_svm(m_gamma=8.3):\n",
    "    return SVC(gamma=gamma, C=10, kernel='rbf')\n",
    "\n",
    "def get_mlp(input_shape, n_classes):\n",
    "    X_input = Dense(100, input_shape=input_shape, activation='tanh')\n",
    "    X = Dense(30, activation='tanh')(X)\n",
    "    X = Dense(30, activation='tanh')(X)\n",
    "    X = Dense(30, activation='tanh')(X)\n",
    "    X = Dense(30, activation='tanh')(X)\n",
    "    X = Dense(30, activation='tanh')(X)\n",
    "    X = Dense(30, activation='tanh')(X)\n",
    "    X_out = Dense(n_classes, activation='softmax')(X)\n",
    "    model = Model(inputs=X_inputs, outputs=X_out, name='Simple MLP')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBkU0QqwF-Yb"
   },
   "source": [
    "### Create and train  models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMWDwJmIp9qo"
   },
   "source": [
    "#### Evaluatin Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkuIxVvbqA_1"
   },
   "outputs": [],
   "source": [
    "def calculate_mean_and_stdd(list_of_values):\n",
    "    \"\"\"\n",
    "    Calculates the mean and standard deviation of a set\n",
    "    :param list_of_values:\n",
    "    :return: mean and standard deviation\n",
    "    \"\"\"\n",
    "    mean = 0\n",
    "    stdd = 0\n",
    "    set_size = len(list_of_values)\n",
    "    for acc in list_of_values:\n",
    "        mean += acc\n",
    "    mean = mean/set_size\n",
    "    for acc in list_of_values:\n",
    "        stdd += np.power(acc - mean, 2)\n",
    "    stdd = np.sqrt(stdd/set_size)\n",
    "\n",
    "    return mean, stdd\n",
    "\n",
    "def evaluate_model(test_data, test_labels, batch_size, model, n_epochs, H, n_classes,\n",
    "                   dataset_name, sub_dataset_name, model_folder,window_size=\"\", save_results=False):\n",
    "    ## Evaluating model\n",
    "    print(\"[INFO] Evaluating Network\")\n",
    "    super_exp_folder = experiments_folder + model_folder + dataset_name\n",
    "    sub_exp_folder = experiments_folder + model_folder + dataset_name + sub_dataset_name\n",
    "    window_file = sub_exp_folder+\"window_\"+window_size+\"_\"\n",
    "\n",
    "    if save_results and not os.path.exists(experiments_folder+model_folder):\n",
    "        os.mkdir(experiments_folder+model_folder)\n",
    "\n",
    "    if save_results and not os.path.exists(super_exp_folder):\n",
    "        os.mkdir(super_exp_folder)\n",
    "\n",
    "    if save_results and not os.path.exists(sub_exp_folder):\n",
    "        os.mkdir(sub_exp_folder)\n",
    "        #if window_size != \"\":\n",
    "        #   os.mkdir(sub_exp_folder+\"window_\"+window_size+\"/\")\n",
    "\n",
    "    if save_results:\n",
    "        train_mean_acc, train_stdd_acc = calculate_mean_and_stdd(H.history[\"acc\"])\n",
    "        val_mean_acc, val_stdd_acc = calculate_mean_and_stdd(H.history[\"val_acc\"])\n",
    "\n",
    "        with open(window_file + \"eval.txt\", 'w') as f:\n",
    "            predictions = model.predict(test_data, batch_size=batch_size)\n",
    "            value = classification_report(test_labels.argmax(axis=1),\n",
    "                                          predictions.argmax(axis=1))\n",
    "            value += \"\\nTrain acc mean: \"+str(train_mean_acc)+\"\\t ,Train acc stdd: \"+str(train_stdd_acc)\n",
    "            value += \"\\nValidation acc mean: \" + str(val_mean_acc) + \"\\t ,Validation acc stdd: \" + str(val_stdd_acc)+ \"\\n\\n\"\n",
    "            print(value)\n",
    "            f.write(value)\n",
    "            f.close()\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, n_epochs), H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, n_epochs), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(np.arange(0, n_epochs), H.history[\"acc\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, n_epochs), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    if window_size != \"\":\n",
    "        plt.title(\"Training Loss and Accuracy Window \"+window_size)\n",
    "    else:\n",
    "        plt.title(\"Training Loss and Accuracy\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    if save_results:\n",
    "        plt.savefig(window_file + \"LossAccComparison.png\")\n",
    "        plt.close('all')\n",
    "\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3dCn_7Ek02kY"
   },
   "source": [
    "#### Classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1237
    },
    "colab_type": "code",
    "id": "AOAjUTVlDs1_",
    "outputId": "fa8b693e-1aa3-4df5-b0d7-8a3f83f20de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training Network\n",
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/20\n",
      "240/240 [==============================] - 1s 5ms/step - loss: 0.4582 - acc: 0.8500 - val_loss: 0.0486 - val_acc: 0.9833\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.3498 - acc: 0.9250 - val_loss: 0.0110 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.2613 - acc: 0.9375 - val_loss: 0.1239 - val_acc: 0.9667\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1138 - acc: 0.9625 - val_loss: 0.0700 - val_acc: 0.9667\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0824 - acc: 0.9792 - val_loss: 0.0124 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1010 - acc: 0.9792 - val_loss: 0.0781 - val_acc: 0.9667\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.1269 - acc: 0.9625 - val_loss: 0.0195 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0660 - acc: 0.9917 - val_loss: 0.0159 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0805 - acc: 0.9792 - val_loss: 0.0089 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0244 - acc: 0.9917 - val_loss: 0.0101 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0166 - acc: 0.9917 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0149 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0359 - acc: 0.9875 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0222 - acc: 0.9875 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0082 - acc: 0.9958 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0107 - acc: 0.9958 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "[INFO] Evaluating Network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         9\n",
      "           3       1.00      1.00      1.00        27\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEaCAYAAAAL7cBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wO/s0Z6hvsLlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Conv nets\n",
    "global input_shape,n_classes\n",
    "train_data,train_labels,test_data,test_labels = load_and_split(1,ds_idx=0)\n",
    "                                                              \n",
    "train_data,test_data = standardize_data(train_data,test_data)\n",
    "\n",
    "batch_size  = 10\n",
    "epochs = 20\n",
    "lr = .001\n",
    "\n",
    "#model = sniffnet(input_shape,n_classes)\n",
    "model = sniffresnet(input_shape,n_classes)\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=lr,momentum=.9),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "train_labels  = keras.utils.to_categorical(train_labels,n_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, n_classes)\n",
    "\n",
    "print(\"[INFO] Training Network\")\n",
    "H = model.fit(train_data,train_labels,batch_size=batch_size,\n",
    "         epochs=epochs,verbose=1,validation_data=(test_data,test_labels))\n",
    "\n",
    "evaluate_model(test_data,test_labels,batch_size,model,H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEDgl8Dmlury"
   },
   "source": [
    "#### Funsion SniffNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Eep6XH8lesn"
   },
   "outputs": [],
   "source": [
    "#Fusion SniffNet\n",
    "global n_classes, input_shape\n",
    "train_data, train_labels, test_data, test_labels = load_and_split(1,\n",
    "                                                                  read_wine_datasets=True)\n",
    "                                                                 \n",
    "\n",
    "# normalizing data\n",
    "train_data, test_data = standardize_data(train_data, test_data)\n",
    "\n",
    "train_data = split_datasamples_by_sensors(train_data)\n",
    "test_data = split_datasamples_by_sensors(test_data)\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 20\n",
    "lr = .001\n",
    "\n",
    "train_labels = keras.utils.to_categorical(train_labels, n_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, n_classes)\n",
    "# defining model\n",
    "model = sniffmultinose(input_shape, n_classes)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=lr, momentum=.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "H = model.fit(train_data, train_labels, batch_size=batch_size,\n",
    "              epochs=epochs, verbose=1, validation_data=(test_data, test_labels))\n",
    "\n",
    "evaluate_model(test_data, test_labels, batch_size, model, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CgFIhEqo6RB"
   },
   "source": [
    "#### Create and print model configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrp5TV3QpDn2"
   },
   "outputs": [],
   "source": [
    "global n_classes, input_shape\n",
    "train_data, train_labels, test_data, test_labels = load_and_split(2,ds_idx=0)\n",
    "\n",
    "print(\"\\t\\tSniffConvNet sumarry\\n\\n\")\n",
    "sniffnet(input_shape,n_classes).sumary()\n",
    "\n",
    "print(\"\\t\\tSniffResNet sumarry\\n\\n\")\n",
    "sniffresnet(input_shape,n_classes).sumary()\n",
    "\n",
    "print(\"\\t\\tSniffMultinose sumarry\\n\\n\")\n",
    "sniffmultinose(input_shape, n_classes).sumary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-4i4kcCNJb0"
   },
   "source": [
    "# Windowed Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdD6hjHXyVKn"
   },
   "outputs": [],
   "source": [
    "def write_csv(path,file_name,data,mode=\"w+\"):\n",
    "\n",
    "    if \".csv\" not in file_name:\n",
    "        file_name += \".csv\"\n",
    "    with open(path+file_name,mode) as f:\n",
    "        csv_writer = csv.writer(f, delimiter=',')\n",
    "        csv_writer.writerows(data)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLCOWempNM-3"
   },
   "outputs": [],
   "source": [
    "def resettv(samp=1):\n",
    "    \"\"\"\n",
    "    Setting the parameters for running the windowed experiment\n",
    "    :param samp: The samp value\n",
    "    :return: the parameters\n",
    "    \"\"\"\n",
    "    parameters = {\"fonollosa\": {\"ini_value\": int(5000/5),\n",
    "                                \"start_value\": int(6400/5),\n",
    "                                \"step\": int(1400/5),\n",
    "                                \"end_value\": int(19000/5)+1,\n",
    "                                },\n",
    "                  \"windtunnel\": {\"ini_value\": int(20*samp),\n",
    "                                  \"start_value\": int(44*samp),\n",
    "                                  \"step\": int(23*samp),\n",
    "                                  \"end_value\": int(260*samp)},\n",
    "                  \"turbulent_gas_mixtures\": {\"ini_value\": int(600/samp),\n",
    "                                             \"start_value\": int(837/samp),\n",
    "                                             \"step\": int(236/samp),\n",
    "                                             \"end_value\": int(2970/samp)},\n",
    "                  \"QWines-CsystemTR\": {\"ini_value\": int(160/samp),\n",
    "                                       \"start_value\": int(474/samp),\n",
    "                                       \"step\": int(314/samp),\n",
    "                                       \"end_value\": int(3300/samp) + 1},\n",
    "                  \"QWinesEa-CsystemTR\": {\"ini_value\": int(160/samp),\n",
    "                                         \"start_value\": int(474/samp),\n",
    "                                         \"step\": int(314/samp),\n",
    "                                         \"end_value\": int(3300/samp) + 1}\n",
    "                  # Uncomment the following lines if you have been authorized to \n",
    "                  #,\"coffee_dataset\": {\"ini_value\": int(29/samp),\n",
    "                  #                   \"start_value\": int(56/samp),\n",
    "                  #                   \"step\": int(26/samp),\n",
    "                  #                   \"end_value\": int(299/samp)}\n",
    "                  }\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def load_dataset(ds_choice, ds_idx, read_wine_datasets=False):\n",
    "    \"\"\"\n",
    "    Loads the dataset from the experiment\n",
    "    :param ds_choice: Name of the dataset_chosen\n",
    "    :param ds_idx: index indicating wich subset should be loaded\n",
    "    :param read_wine_datasets:  True, if it is desired to read the wine dataset\n",
    "    :return: data_samples,\n",
    "            data labels,\n",
    "            name of the dataset and name of the data subset,\n",
    "            name of the input_shape\n",
    "    \"\"\"\n",
    "    data = None\n",
    "    labels = None\n",
    "    dataset_name = None\n",
    "    sub_dataset_name = None\n",
    "    if not read_wine_datasets:\n",
    "        data, labels, n_classes, dataset_name, sub_dataset_name = load(ds_choice, ds_idx)\n",
    "    else:\n",
    "        data, labels, n_classes, dataset_name, sub_dataset_name = load_wine(ds_choice)\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    input_shape = data[0].shape\n",
    "\n",
    "    return data, labels, n_classes, dataset_name, sub_dataset_name, input_shape\n",
    "\n",
    "\n",
    "def run_windowed_experiment():\n",
    "    parameters = resettv()\n",
    "    list_of_keys = list(parameters.keys())\n",
    "\n",
    "    # Creating indexes for each dataset being loaded\n",
    "  \n",
    "    datasets_names = {'fonollosa': [0, 1, 2, 3, 4],#  \n",
    "                      'turbulent_gas_mixtures': [0],\n",
    "                      'windtunnel': [0, 1, 2, 3, 4, 5]\n",
    "                      # Un comment the following line \n",
    "                      # if you have been authorized to use the cofee dataset\n",
    "                      #,'coffee_dataset': [0]\n",
    "                      }\n",
    "\n",
    "    batch_size = 10\n",
    "    epochs = 20\n",
    "    lr = .001\n",
    "\n",
    "    names_list = list(datasets_names.keys())\n",
    "    # Taking the parameters for fonollosa dataset as a test case\n",
    "    # Iterating over model type, where the all the model types created are the normal ConvNet, Resnet an FusionNEt\n",
    "    # Where for the fusion net the data needs a special treatment\n",
    "    # models_names = [\"SniffConvNet\", \"SniffResnet\", \"SniffMultinose\"]\n",
    "    models_names = [(0, \"SniffConvNet\"), (1, \"SniffResnet\"), (2, \"SniffMultinose\")]\n",
    "    \n",
    "    \n",
    "    for (model_type, m_name) in models_names:\n",
    "        print(\"\\n\\tUsin \" + m_name + \" architechture\\n\")\n",
    "        model_folder = m_name + \"/\"\n",
    "        # Interating over dataset names\n",
    "        for i, name in enumerate(names_list):\n",
    "            print(\"\\n\\tDataset \" + name + \"\\n\")\n",
    "            sub_set_index = datasets_names[name]\n",
    "            # Iterating over subset indexes\n",
    "            for ss_idx in sub_set_index:\n",
    "                print(\"\\n\\n ds_name:\"+name+\"\\n\\n\")\n",
    "                print(\"\\n\\n ds_idx:\"+str(ss_idx)+\"\\n\\n\")\n",
    "                f_params = parameters[name]\n",
    "                data, labels, n_classes, dataset_name, sub_dataset_name, input_shape = load_dataset(name, ss_idx,\n",
    "                                                                                                    read_wine_datasets=False)\n",
    "                time_estimate_list = []\n",
    "                toc = time.time()\n",
    "                n_windows_processed = 0\n",
    "                data, labels = sklearn.utils.shuffle(data, labels)\n",
    "                for final_measurement in range(f_params['start_value'], f_params['end_value'], f_params['step']):\n",
    "                    print(\"\\n\\n\\t Window\", final_measurement)\n",
    "                    print(\"\\n\\n\")\n",
    "                    print(\"\\n\\tSubset \" + sub_dataset_name + \"\\n\")\n",
    "                    train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "                        data[:, f_params['ini_value']:final_measurement, :],\n",
    "                        labels, test_size=0.2)\n",
    "                    # Normalizing data\n",
    "                    train_data, test_data = standardize_data(train_data, test_data, test_data.shape[1:])\n",
    "\n",
    "                    train_labels = keras.utils.to_categorical(train_labels, n_classes)\n",
    "                    test_labels = keras.utils.to_categorical(test_labels, n_classes)\n",
    "\n",
    "                    if model_type == 2:\n",
    "                        # Reshapes data if usign the SniffMultinose\n",
    "                        train_data = data_set_reshaped(train_data)\n",
    "                        test_data = data_set_reshaped(test_data)\n",
    "                        input_shape = train_data[0].shape\n",
    "                        train_data = split_datasamples_by_sensors(train_data)\n",
    "                        test_data = split_datasamples_by_sensors(test_data)\n",
    "\n",
    "                    # defining model\n",
    "                    model = None\n",
    "                    if model_type == 0:\n",
    "                        model = sniffnet(train_data.shape[1:], n_classes)\n",
    "                    elif model_type == 1:\n",
    "                        model = sniffresnet(train_data.shape[1:], n_classes)\n",
    "                    elif model_type == 2:\n",
    "                        model = sniffmultinose(input_shape, n_classes)\n",
    "                    elif model_type == 3:\n",
    "                        model = get_svm()\n",
    "                    print(\"Model \" + m_name + \" has been created\")\n",
    "\n",
    "                    model.compile(loss=\"categorical_crossentropy\",\n",
    "                                  optimizer=keras.optimizers.SGD(lr=lr, momentum=.9),\n",
    "                                  metrics=['accuracy'])\n",
    "                    H = model.fit(train_data, train_labels, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                                  validation_data=(test_data, test_labels))\n",
    "\n",
    "                    n_windows_processed += 1\n",
    "                    \n",
    "                    evaluate_model(test_data, test_labels, batch_size, model, epochs, H, n_classes,\n",
    "                                   dataset_name, sub_dataset_name, model_folder,\n",
    "                                   window_size=str(final_measurement), save_results=True)\n",
    "                    \n",
    "                tic = time.time()\n",
    "                time_estimate_set_names = name+\" \"+sub_dataset_name\n",
    "                total_estimate = tic - toc\n",
    "                time_estimate_list.append([m_name,time_estimate_set_names,\n",
    "                                           total_estimate, \n",
    "                                           n_windows_processed])\n",
    "                #write_csv(\"drive/My Drive/\",\"time_estimates_wt_fon_tgm_coff.csv\",\n",
    "                          #time_estimate_list,\n",
    "                          #mode='a+')\n",
    "\n",
    "\n",
    "\n",
    "def run_windowed_experiment_for_wine_dataset():\n",
    "    print(\"\\n\\n\\tExecuting experinment of wines dataset\\n\\n\")\n",
    "    parameters = resettv()\n",
    "    list_of_keys = list(parameters.keys())\n",
    "\n",
    "    # Creating indexes for each dataset being loaded\n",
    "    names_list = [\"QWines-CsystemTR\", \"QWinesEa-CsystemTR\"]\n",
    "\n",
    "    batch_size = 10\n",
    "    epochs = 20\n",
    "    lr = .001\n",
    "\n",
    "    # Taking the parameters for fonollosa dataset as a test case\n",
    "    # Iterating over model type, where the all the model types created are the normal ConvNet, Resnet an FusionNEt\n",
    "    # Where for the fusion net the data needs a special treatment\n",
    "    models_names = [(0, \"SniffConvNet\"), (1, \"SniffResnet\"), (2, \"SniffMultinose\")]#\n",
    "    \n",
    "    for (model_type, m_name) in models_names:\n",
    "        print(\"\\n\\tUsin \" + m_name + \" architechture\\n\")\n",
    "        model_folder = m_name + \"/\"\n",
    "\n",
    "        # Interating over dataset names\n",
    "        for i, name in enumerate(names_list):\n",
    "            print(\"\\n\\tDataset \" + name + \"\\n\")\n",
    "            # Iterating over subset indexes\n",
    "            f_params = parameters[name]\n",
    "            data, labels, n_classes, dataset_name, sub_dataset_name, input_shape = load_dataset(name, 0,\n",
    "                                                                                                read_wine_datasets=True)\n",
    "            \n",
    "            time_estimate_list = []\n",
    "            toc = time.time()\n",
    "            n_windows_processed = 0\n",
    "            data, labels = sklearn.utils.shuffle(data, labels)            \n",
    "            for final_measurement in range(f_params['start_value'], f_params['end_value'], f_params['step']):\n",
    "                print(\"\\n\\n\\t Window\", final_measurement)\n",
    "                print(\"\\n\\n\")\n",
    "                train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "                    data[:, f_params['ini_value']:final_measurement, :],\n",
    "                    labels, test_size=0.2)\n",
    "                # Normalizing data\n",
    "                train_data, test_data = standardize_data(train_data, test_data, test_data.shape[1:])\n",
    "                # Reshaping data\n",
    "                # train_data = train_data.reshape(train_data.shape[0], train_data.shape[1], train_data.shape[2], 1)\n",
    "                # test_data = test_data.reshape(test_data.shape[0], test_data.shape[1], test_data.shape[2], 1)\n",
    "\n",
    "                train_labels = keras.utils.to_categorical(train_labels, n_classes)\n",
    "                test_labels = keras.utils.to_categorical(test_labels, n_classes)\n",
    "\n",
    "                # defining model\n",
    "                if model_type == 2:\n",
    "                    # Reshapes data if usign the SniffMultinose\n",
    "                    train_data = data_set_reshaped(train_data)\n",
    "                    test_data = data_set_reshaped(test_data)\n",
    "                    input_shape = train_data[0].shape\n",
    "                    train_data = split_datasamples_by_sensors(train_data)\n",
    "                    test_data = split_datasamples_by_sensors(test_data)\n",
    "\n",
    "                # defining model\n",
    "                model = None\n",
    "                if model_type == 0:\n",
    "                    model = sniffnet(train_data.shape[1:], n_classes)\n",
    "                elif model_type == 1:\n",
    "                    model = sniffresnet(train_data.shape[1:], n_classes)\n",
    "                elif model_type == 2:\n",
    "                    model = sniffmultinose(input_shape, n_classes)\n",
    "                print(\"Model \" + m_name + \" has been created\")\n",
    "\n",
    "                model.compile(loss=\"categorical_crossentropy\",\n",
    "                              optimizer=keras.optimizers.SGD(lr=lr, momentum=.9),\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "                H = model.fit(train_data, train_labels, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                              validation_data=(test_data, test_labels))\n",
    "                n_windows_processed += 1\n",
    "                evaluate_model(test_data, test_labels, batch_size, model, epochs, H, n_classes,\n",
    "                               dataset_name, sub_dataset_name, model_folder,\n",
    "                               window_size=str(final_measurement), save_results=True)\n",
    "            tic = time.time()\n",
    "            time_estimate_set_names = name+\" \"+sub_dataset_name\n",
    "            total_estimate = tic - toc\n",
    "            time_estimate_list.append([m_name,time_estimate_set_names,\n",
    "                                        total_estimate, \n",
    "                                        n_windows_processed])          \n",
    "            write_csv(\"drive/My Drive/\",\"time_estimates_wine.csv\",time_estimate_list,\n",
    "                      mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "4WKfXJLw1wyO",
    "outputId": "9f79abb0-4dfc-413c-fa8b-2d19bba0c119"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['model type',\n",
       "  'datset and sub dataset name',\n",
       "  'total_execution_time',\n",
       "  'windows_processed']]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating csv header\n",
    "time_estimate_list_titles = [[\"model type\",\n",
    "                              \"datset and sub dataset name\",\n",
    "                              \"total_execution_time\",\n",
    "                              \"windows_processed\"]]\n",
    "time_estimate_list_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7E4CJE7AKuqV"
   },
   "outputs": [],
   "source": [
    "write_csv(\"drive/My Drive/\",\"time_estimates_wt_fon_tgm.csv\",time_estimate_list_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVTiHLPMNQFC"
   },
   "outputs": [],
   "source": [
    "run_windowed_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lywwuRw2KyIA"
   },
   "outputs": [],
   "source": [
    "write_csv(\"drive/My Drive/\",\"time_estimates_wine.csv\",time_estimate_list_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrAL_6lHOA5P"
   },
   "outputs": [],
   "source": [
    "run_windowed_experiment_for_wine_dataset()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "3dCn_7Ek02kY",
    "FEDgl8Dmlury"
   ],
   "name": "projeto_final_DL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
